{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eceafd2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eceafd2a",
    "outputId": "b1e6a8bb-4e78-4c40-e3e4-63aed349315d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/szagoruyko/pytorchviz.git@master\n",
      "  Cloning https://github.com/szagoruyko/pytorchviz.git (to revision master) to /tmp/pip-req-build-h1bnq39n\n",
      "  Running command git clone -q https://github.com/szagoruyko/pytorchviz.git /tmp/pip-req-build-h1bnq39n\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz==0.0.2) (1.11.0+cu113)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz==0.0.2) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz==0.0.2) (4.2.0)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from skimage import filters\n",
    "from skimage import feature\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "from skimage.io import imread, imshow\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "%pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import time\n",
    "import torch\n",
    "import imghdr\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defbdc64",
   "metadata": {
    "id": "defbdc64"
   },
   "outputs": [],
   "source": [
    "parent=r'C:\\Users\\Abdul Wahid Awan\\Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690dadd6",
   "metadata": {
    "id": "690dadd6"
   },
   "outputs": [],
   "source": [
    "featured_path=parent+'\\Copy\\FeaturedImages'\n",
    "# featured_path ='/content/drive/MyDrive/FeaturedImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "MufeSQic1Zzp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MufeSQic1Zzp",
    "outputId": "071818be-e7a5-47f7-a819-5cfdf05c631d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b75878",
   "metadata": {
    "id": "e7b75878"
   },
   "source": [
    "# Glove 6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567a8252",
   "metadata": {
    "id": "567a8252"
   },
   "outputs": [],
   "source": [
    "glove_path=\"/content/drive/MyDrive/Glove_6B\"\n",
    "# glove_path=parent+\"\\Glove6B\"\n",
    "os.chdir(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53105fc2",
   "metadata": {
    "id": "53105fc2"
   },
   "outputs": [],
   "source": [
    "def glove_model(glove_path):\n",
    "    glove_dict = {}\n",
    "    with open(glove_path+'/'+'glove.6B.300d.txt','r',encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            string = line.split()\n",
    "            word = string[0]\n",
    "            feature = np.array(string[1:], dtype=np.float64)\n",
    "            glove_dict[word] = feature\n",
    "    return glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63e6c9c",
   "metadata": {
    "id": "f63e6c9c"
   },
   "outputs": [],
   "source": [
    "glove=glove_model(glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb6e5f",
   "metadata": {
    "id": "89fb6e5f"
   },
   "source": [
    "# All Images DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16101f",
   "metadata": {
    "id": "ff16101f"
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\Abdul Wahid Awan\\Downloads\\Copy\")\n",
    "df=pd.read_csv(\"ALL.csv\")\n",
    "df.loc[df['overall_sentiment'] =='0' , 'overall_sentiment'] = 1\n",
    "df.loc[df['overall_sentiment'] =='1' , 'overall_sentiment'] = 2\n",
    "df.loc[df['overall_sentiment'] =='2' , 'overall_sentiment'] = 0\n",
    "\n",
    "df.loc[df['humour'] =='funny' , 'humour'] = 1\n",
    "df.loc[df['humour'] =='very_funny' , 'humour'] = 1\n",
    "df.loc[df['humour'] =='hilarious' , 'humour'] = 1\n",
    "df.loc[df['humour'] =='not_funny' , 'humour'] = 0\n",
    "\n",
    "\n",
    "df.loc[df['sarcasm'] =='general' , 'sarcasm'] = 1\n",
    "df.loc[df['sarcasm'] =='twisted_meaning' , 'sarcasm'] = 1\n",
    "df.loc[df['sarcasm'] =='very_twisted' , 'sarcasm'] = 1\n",
    "df.loc[df['sarcasm'] =='not_sarcastic' , 'sarcasm'] = 0\n",
    "\n",
    "\n",
    "df.loc[df['offensive'] =='offensive' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='slight' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='hateful_offensive' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='very_offensive' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='not_offensive' , 'offensive'] = 0\n",
    "\n",
    "df.loc[df['motivational'] =='not_motivational' , 'motivational'] = 0\n",
    "df.loc[df['motivational'] =='motivational' , 'motivational'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d74f8",
   "metadata": {
    "id": "839d74f8"
   },
   "outputs": [],
   "source": [
    "df.to_csv('ALLnew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb6aa78",
   "metadata": {
    "id": "cbb6aa78"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/MyDrive/Project_AI')\n",
    "df=pd.read_csv(\"ALLnew.csv\")\n",
    "df=df.drop(labels=\"Unnamed: 0.1\",axis=1)\n",
    "df=df.drop(labels=\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f2c7205",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "7f2c7205",
    "outputId": "2e773bd2-2e2e-4412-fd2b-4713d7811206"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-27879327-2629-4099-b788-d3ea51ff9f43\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12948</th>\n",
       "      <td>image_6961_rotated180FLR.jpeg</td>\n",
       "      <td>THAT FACE YOUR FRIEND GIVES YOU WHEN YOUR CRUS...</td>\n",
       "      <td>THAT FACE YOUR FRIEND GIVES YOU WHEN YOUR CRUS...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12949</th>\n",
       "      <td>image_6962_rotated180FLR.jpeg</td>\n",
       "      <td>NIGHTMARES Are made of this.</td>\n",
       "      <td>NIGHTMARES Are made of this.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12950</th>\n",
       "      <td>image_6966_rotated180FLR.png</td>\n",
       "      <td>Baby Mr. Bean Funny Picture</td>\n",
       "      <td>Baby Mr. Bean Funny Picture</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12951</th>\n",
       "      <td>image_6972_rotated180FLR.jpeg</td>\n",
       "      <td>YOUR FACE MemeCenter.com WHEN THERES A SUBSTIT...</td>\n",
       "      <td>YOUR FACE MemeCenter.com WHEN THERES A SUBSTIT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12952</th>\n",
       "      <td>image_6983_rotated180FLR.jpeg</td>\n",
       "      <td>Rider 999999 elle STILLS RRA 224 NOTHING! KNOW...</td>\n",
       "      <td>I STILL KNOW NOTHING! 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12953 rows Ã— 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27879327-2629-4099-b788-d3ea51ff9f43')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-27879327-2629-4099-b788-d3ea51ff9f43 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-27879327-2629-4099-b788-d3ea51ff9f43');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                          image_name  \\\n",
       "0                        image_1.jpg   \n",
       "1                       image_2.jpeg   \n",
       "2                        image_3.JPG   \n",
       "3                        image_4.png   \n",
       "4                        image_5.png   \n",
       "...                              ...   \n",
       "12948  image_6961_rotated180FLR.jpeg   \n",
       "12949  image_6962_rotated180FLR.jpeg   \n",
       "12950   image_6966_rotated180FLR.png   \n",
       "12951  image_6972_rotated180FLR.jpeg   \n",
       "12952  image_6983_rotated180FLR.jpeg   \n",
       "\n",
       "                                                text_ocr  \\\n",
       "0      LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1      The best of #10 YearChallenge! Completed in le...   \n",
       "2      Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3                  10 Year Challenge - Sweet Dee Edition   \n",
       "4      10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "...                                                  ...   \n",
       "12948  THAT FACE YOUR FRIEND GIVES YOU WHEN YOUR CRUS...   \n",
       "12949                       NIGHTMARES Are made of this.   \n",
       "12950                        Baby Mr. Bean Funny Picture   \n",
       "12951  YOUR FACE MemeCenter.com WHEN THERES A SUBSTIT...   \n",
       "12952  Rider 999999 elle STILLS RRA 224 NOTHING! KNOW...   \n",
       "\n",
       "                                          text_corrected  humour  sarcasm  \\\n",
       "0      LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...       1        1   \n",
       "1      The best of #10 YearChallenge! Completed in le...       0        1   \n",
       "2      Sam Thorne @Strippin ( Follow Follow Saw every...       1        0   \n",
       "3                  10 Year Challenge - Sweet Dee Edition       1        1   \n",
       "4      10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...       1        1   \n",
       "...                                                  ...     ...      ...   \n",
       "12948  THAT FACE YOUR FRIEND GIVES YOU WHEN YOUR CRUS...       1        1   \n",
       "12949                       NIGHTMARES Are made of this.       0        0   \n",
       "12950                        Baby Mr. Bean Funny Picture       1        1   \n",
       "12951  YOUR FACE MemeCenter.com WHEN THERES A SUBSTIT...       1        1   \n",
       "12952                         I STILL KNOW NOTHING! 2017       1        1   \n",
       "\n",
       "       offensive  motivational  overall_sentiment  \n",
       "0              0             0                  0  \n",
       "1              0             1                  0  \n",
       "2              0             0                  0  \n",
       "3              1             1                  0  \n",
       "4              1             0                  2  \n",
       "...          ...           ...                ...  \n",
       "12948          1             0                  1  \n",
       "12949          0             1                  1  \n",
       "12950          1             0                  1  \n",
       "12951          1             0                  1  \n",
       "12952          1             0                  1  \n",
       "\n",
       "[12953 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3e085",
   "metadata": {
    "id": "45c3e085"
   },
   "source": [
    "# Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025686e2",
   "metadata": {
    "id": "025686e2"
   },
   "outputs": [],
   "source": [
    "def image_features(img):\n",
    "    os.chdir(featured_path)\n",
    "    image1 =imread(img,as_gray=True)\n",
    "    feature =np.array(image1,dtype='float32')\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefb866d",
   "metadata": {
    "id": "cefb866d"
   },
   "outputs": [],
   "source": [
    "def text_features(img):\n",
    "    os.chdir(featured_path)\n",
    "    feature=[]\n",
    "    line=df[df['image_name'] ==img]['text_corrected'].iloc[0]\n",
    "    text=line\n",
    "    text=text.lower()\n",
    "    words=word_tokenize(text)\n",
    "    for j in words:\n",
    "        try:\n",
    "            feature.append(glove[j])\n",
    "        except:\n",
    "            pass\n",
    "    feature=np.array(feature).flatten()\n",
    "    maxi=62100\n",
    "    feature=np.pad(feature,(0,maxi-len(feature)))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310a18d",
   "metadata": {
    "id": "2310a18d"
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780363c1",
   "metadata": {
    "id": "780363c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,df,train,test):\n",
    "        self.all_images = (np.array(df['image_name'])).tolist()\n",
    "        self.labels = (np.array(df[['humour','sarcasm','offensive','motivational']])).tolist()\n",
    "        self.train_images = int((len(df)*0.8))\n",
    "        self.valid_ratio = len(df) - self.train_images\n",
    "       \n",
    "        \n",
    "        if train == True:\n",
    "            self.images = self.all_images[:self.train_images]\n",
    "            self.label = self.labels[:self.train_images]\n",
    "\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((270, 275)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=90),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "            \n",
    "        elif test==True:\n",
    "            self.images = list(self.all_images[-self.valid_ratio:])\n",
    "            self.label = list(self.labels[-self.valid_ratio:])\n",
    "            \n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((270, 275)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "           \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        tf= text_features(self.images[position])\n",
    "        img = image_features(self.images[position])\n",
    "        img = self.transform(img)\n",
    "        img = img.flatten()\n",
    "        outputlabel = self.label[position]\n",
    "       \n",
    "        outputlabel= torch.tensor(outputlabel, dtype=torch.float32)\n",
    "        img= torch.tensor(img, dtype=torch.float32)\n",
    "        tf=  torch.tensor(tf, dtype=torch.float32)\n",
    "        dict1= {\"Image\":img,\"Text\":tf,\"OutputLabel\":outputlabel}\n",
    "\n",
    "        return dict1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a60db4",
   "metadata": {
    "id": "d5a60db4"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a90d4f7",
   "metadata": {
    "id": "1a90d4f7"
   },
   "outputs": [],
   "source": [
    "class Multi_Model_NN(nn.Module):\n",
    "    def __init__(self,textinput,inputneurons,textH1,textH2,comH1,ImageH1,ImageH2,all4,ImageH3,textH3,ImageH4,comH2,comH3,sh1,sh2,Hh1,Hh2,mh1,mh2,oh1,oh2,outall):\n",
    "        super(Multi_Model_NN, self).__init__()\n",
    "        \n",
    "        self.text = nn.Sequential(\n",
    "            nn.Linear(textinput, textH1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(textH1, textH2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(textH2, textH3)\n",
    "       )\n",
    "        self.image = nn.Sequential(\n",
    "            nn.Linear(inputneurons,ImageH1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(ImageH1, ImageH2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(ImageH2, ImageH3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ImageH3, ImageH4)\n",
    "        )\n",
    "        \n",
    "        self.combination_of_models = nn.Sequential(\n",
    "            nn.Linear(textH3+ImageH4,comH1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(comH1,comH2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(comH2,comH3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(comH3,all4)\n",
    "        )\n",
    "        \n",
    "        self.sarcasm = nn.Sequential(\n",
    "            nn.Linear(all4, sh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(sh1, sh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(sh2, outall),\n",
    "        )\n",
    "        \n",
    "        self.humour = nn.Sequential(\n",
    "            nn.Linear(all4, Hh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hh1, Hh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hh2, outall),\n",
    "        )\n",
    "\n",
    "        self.motivational = nn.Sequential(\n",
    "            nn.Linear(all4, mh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mh1, mh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mh2, outall),\n",
    "        )\n",
    "\n",
    "        self.offensive = nn.Sequential(\n",
    "            nn.Linear(all4, oh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(oh1, oh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(oh2, outall),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_output = self.image(img)\n",
    "        t_output = self.text(text)\n",
    "\n",
    "        dual = torch.cat([t_output,img_output],1)\n",
    "        x = self.combination_of_models(dual)\n",
    "        \n",
    "        o_out = self.offensive(x)\n",
    "        m_out = self.motivational(x)\n",
    "        h_out = self.humour(x)\n",
    "        s_out = self.sarcasm(x)\n",
    "        \n",
    "        return o_out,m_out,h_out,s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e97339ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e97339ed",
    "outputId": "476b6d4e-a363-46a5-e021-eb6c6631eb00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Multi_Model_NN(\n",
      "  (text): Sequential(\n",
      "    (0): Linear(in_features=62100, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=700, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=700, out_features=400, bias=True)\n",
      "  )\n",
      "  (image): Sequential(\n",
      "    (0): Linear(in_features=74250, out_features=1000, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=1000, out_features=800, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=800, out_features=600, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=600, out_features=400, bias=True)\n",
      "  )\n",
      "  (combination_of_models): Sequential(\n",
      "    (0): Linear(in_features=800, out_features=700, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=700, out_features=650, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=650, out_features=600, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=600, out_features=500, bias=True)\n",
      "  )\n",
      "  (sarcasm): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=300, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=300, out_features=200, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
      "  )\n",
      "  (humour): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
      "  )\n",
      "  (motivational): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
      "  )\n",
      "  (offensive): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "imginputneurons=74250\n",
    "imghidden1=1000\n",
    "imghidden2=800\n",
    "imghidden3=600\n",
    "imghidden4=400\n",
    "\n",
    "\n",
    "textinput=62100\n",
    "texthidden1=1000\n",
    "texthidden2=700\n",
    "texthidden3=400\n",
    "\n",
    "\n",
    "comh1=700\n",
    "comh2=650\n",
    "comh3=600\n",
    "\n",
    "all4 =500\n",
    "sh1 = 300\n",
    "sh2 = 200\n",
    "\n",
    "Hh1= 400\n",
    "Hh2= 200\n",
    "\n",
    "mh1= 400\n",
    "mh2= 200\n",
    "\n",
    "oh1= 400 \n",
    "oh2= 200\n",
    "outall=2\n",
    "\n",
    "neural_network=Multi_Model_NN(textinput,imginputneurons,texthidden1,texthidden2,comh1,imghidden1,imghidden2,all4,imghidden3,texthidden3,imghidden4,comh2,comh3,sh1,sh2,Hh1,Hh2,mh1,mh2,oh1,oh2,outall)   \n",
    "print(neural_network.parameters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee40ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "7bee40ff",
    "outputId": "1aeb4089-acea-4c3a-b54b-aa8d7168fd30",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoches:  1\n",
      "Epoches:  2\n",
      "Epoches:  3\n",
      "Epoches:  4\n",
      "Epoches:  5\n",
      "Epoches:  6\n",
      "Epoches:  7\n",
      "Epoches:  8\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_data = Data(df, train=True, test=False)\n",
    "loader = DataLoader(training_data, batch_size=60,shuffle=True)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(neural_network.parameters(), lr=0.001)\n",
    "llist = []\n",
    "epoches=8\n",
    "\n",
    "for x in range(epoches):\n",
    "    print(\"Epoches: \",x+1)\n",
    "    for key,value in enumerate(loader):\n",
    "        y_pred = neural_network(value['Image'],value[\"Text\"])\n",
    "        loss = 0\n",
    "        \n",
    "        for i in range(0,len(y_pred)):\n",
    "            loss += criterion(y_pred[i],torch.transpose(value['OutputLabel'],1,0)[i].long()) \n",
    "        \n",
    "        llist.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1a704",
   "metadata": {
    "id": "caa1a704"
   },
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4ae23",
   "metadata": {
    "id": "3cd4ae23"
   },
   "outputs": [],
   "source": [
    "model_path=parent+\"\\model_4labels.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae0c8b",
   "metadata": {
    "id": "68ae0c8b"
   },
   "outputs": [],
   "source": [
    "torch.save(neural_network.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012788d",
   "metadata": {
    "id": "0012788d"
   },
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9630e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1f9630e",
    "outputId": "b1cbd41f-fd96-4f5d-857f-7daa8423ba9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multi_Model_NN(\n",
       "  (text): Sequential(\n",
       "    (0): Linear(in_features=62100, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1000, out_features=700, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=700, out_features=400, bias=True)\n",
       "  )\n",
       "  (image): Sequential(\n",
       "    (0): Linear(in_features=74250, out_features=1000, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=1000, out_features=800, bias=True)\n",
       "    (3): Sigmoid()\n",
       "    (4): Linear(in_features=800, out_features=600, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=600, out_features=400, bias=True)\n",
       "  )\n",
       "  (combination_of_models): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=700, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=700, out_features=650, bias=True)\n",
       "    (3): Sigmoid()\n",
       "    (4): Linear(in_features=650, out_features=600, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=600, out_features=500, bias=True)\n",
       "  )\n",
       "  (sarcasm): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       "  (humour): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       "  (motivational): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       "  (offensive): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodel =Multi_Model_NN(textinput,imginputneurons,texthidden1,texthidden2,comh1,imghidden1,imghidden2,all4,imghidden3,texthidden3,imghidden4,comh2,comh3,sh1,sh2,Hh1,Hh2,mh1,mh2,oh1,oh2,outall)     \n",
    "multimodel.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "multimodel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ba5d8",
   "metadata": {
    "id": "PSJhxSOskuiN"
   },
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cVR0bXE1fG6j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "cVR0bXE1fG6j",
    "outputId": "ad5625e5-d110-43bb-bd15-1b9f56ead1f9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'png/i20_2367_Model_Part2.pdf'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=np.array(df[\"image_name\"])\n",
    "os.chdir(featured_path)\n",
    "\n",
    "temp = Image.open(images[0])\n",
    "temp= temp.convert('L')\n",
    "temp = temp.resize((270,275))\n",
    "\n",
    "feature =np.array(temp,dtype='float32' )\n",
    "feature=feature.flatten()\n",
    "feature=torch.tensor(feature,dtype=torch.float32)\n",
    "\n",
    "t_feature=text_features(images[0])\n",
    "t_feature= torch.tensor(t_feature,dtype=torch.float32)\n",
    "\n",
    "make_dot(neural_network(feature.unsqueeze(0),t_feature.unsqueeze(0)), params=dict(neural_network.named_parameters())).render(\"i20_2367_Model_Part2\",\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be759a6",
   "metadata": {
    "id": "8be759a6"
   },
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aea246de",
   "metadata": {
    "id": "aea246de",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testing_data = Data(df, train=False, test=True)\n",
    "testloader = DataLoader(testing_data, batch_size=60,shuffle=True)\n",
    "\n",
    "llist = []\n",
    "predict=[]\n",
    "actual=[]\n",
    "\n",
    "for key,value in enumerate(testloader):\n",
    "    y_pred = multimodel(value['Image'],value[\"Text\"])\n",
    "    loss = 0\n",
    "    for i in range(0,len(y_pred)):\n",
    "        loss += criterion(y_pred[i],torch.transpose(value['OutputLabel'],1,0)[i].long()) \n",
    "        actual.append(torch.transpose(value['OutputLabel'],1,0)[i].tolist())\n",
    "    \n",
    "    llist.append(loss.item())\n",
    "    for i in range(0,len(y_pred)):\n",
    "        predict.append(torch.argmax(y_pred[i], dim=1).tolist())\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b898b",
   "metadata": {
    "id": "548b898b"
   },
   "outputs": [],
   "source": [
    "actual = list(chain.from_iterable(actual))\n",
    "predict = list(chain.from_iterable(predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3531a4",
   "metadata": {
    "id": "8b3531a4"
   },
   "source": [
    "# Accuracy and F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24bd43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb24bd43",
    "outputId": "7d22894f-6236-4355-b960-381d507eb03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1Score:  66.2664101154715\n",
      "Accuracy:  70.55191045928213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"F1Score: \",f1_score(actual,predict,average='macro')*100)\n",
    "print(\"Accuracy: \",accuracy_score(actual,predict)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9_ECZk7fbExF",
   "metadata": {
    "id": "9_ECZk7fbExF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20i_2367_Project_Part2_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
